{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Google Stock ML - Main Pipeline\n",
    "\n",
    "Modular ML pipeline for predicting Google (GOOGL) stock next-day returns.\n",
    "\n",
    "## Models\n",
    "- **XGBoost** â€” Gradient boosting with 3-stage HPO\n",
    "- **LSTM & GRU** â€” Recurrent neural networks\n",
    "- **Hybrid** â€” Sequential & Parallel architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Colab)\n",
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Add project to path\n",
    "    PROJECT_PATH = '/content/drive/MyDrive/google_stock_ml'\n",
    "    sys.path.insert(0, PROJECT_PATH)\n",
    "else:\n",
    "    # Local development\n",
    "    PROJECT_PATH = '.'\n",
    "    sys.path.insert(0, PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "!pip install -q yfinance xgboost optuna tensorflow scikit-learn pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Project modules\n",
    "from src.config import setup_paths, get_default_params\n",
    "from src.utils import (\n",
    "    save_json, save_pickle, load_pickle, copy_file,\n",
    "    compute_sample_weights, save_run_outputs\n",
    ")\n",
    "from src.data.loaders import load_all_data\n",
    "from src.features.engineering import build_all_features, add_target\n",
    "\n",
    "print(\"[OK] Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths and configuration\n",
    "paths = setup_paths(\n",
    "    drive_project_root=\"/content/drive/MyDrive/my_project\",\n",
    "    local_project_root=\"/content/my_project\"\n",
    ")\n",
    "\n",
    "RUN_PARAMS = get_default_params(paths)\n",
    "\n",
    "# Extract commonly used paths\n",
    "RUN_ID = paths[\"RUN_ID\"]\n",
    "PROJECT_ROOT = paths[\"PROJECT_ROOT\"]\n",
    "LOCAL_PATHS = paths[\"LOCAL_PATHS\"]\n",
    "DRIVE_PATHS = paths[\"DRIVE_PATHS\"]\n",
    "DATA_DIRS_LOCAL = paths[\"DATA_DIRS_LOCAL\"]\n",
    "DATA_DIRS_DRIVE = paths[\"DATA_DIRS_DRIVE\"]\n",
    "\n",
    "print(f\"[CONFIG] RUN_ID: {RUN_ID}\")\n",
    "print(f\"[CONFIG] PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "\n",
    "# Save config\n",
    "save_json(RUN_PARAMS, LOCAL_PATHS[\"config_dir\"] / \"run_params.json\")\n",
    "save_json(RUN_PARAMS, DRIVE_PATHS[\"config_dir\"] / \"run_params.json\")\n",
    "\n",
    "print(\"[OK] Configuration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price tickers\n",
    "PRICE_TICKERS = [\n",
    "    \"GOOGL\", \"MSFT\", \"NVDA\",\n",
    "    \"^IXIC\", \"SPY\", \"QQQ\",\n",
    "    \"^VIX\", \"^TNX\", \"XLK\"\n",
    "]\n",
    "\n",
    "# Date range\n",
    "start = RUN_PARAMS[\"data\"][\"start_date\"]\n",
    "end = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Load all data\n",
    "full_df = load_all_data(\n",
    "    price_tickers=PRICE_TICKERS,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    base_ticker=\"GOOGL\",\n",
    "    eu_config=RUN_PARAMS.get(\"eu_break_close\"),\n",
    "    load_macro=True\n",
    ")\n",
    "\n",
    "print(f\"[OK] Data loaded. Shape: {full_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all features\n",
    "full_df = build_all_features(full_df, RUN_PARAMS)\n",
    "\n",
    "print(f\"[OK] Features built. Shape: {full_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to analysis period\n",
    "limit_date = RUN_PARAMS[\"data\"][\"limit_start_date\"]\n",
    "full_df = full_df[full_df.index >= limit_date].copy()\n",
    "\n",
    "# Drop rows with NaN target\n",
    "TARGET_COL = RUN_PARAMS[\"data\"][\"target_col\"]\n",
    "full_df = full_df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "print(f\"[OK] After limiting: {full_df.shape}\")\n",
    "print(f\"Date range: {full_df.index.min()} to {full_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train/Valid/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dates\n",
    "train_end = RUN_PARAMS[\"data\"][\"train_end\"]\n",
    "valid_start = RUN_PARAMS[\"data\"][\"valid_start\"]\n",
    "valid_end = RUN_PARAMS[\"data\"][\"valid_end\"]\n",
    "test_start = RUN_PARAMS[\"data\"][\"test_start\"]\n",
    "\n",
    "# Create masks\n",
    "dates = full_df.index.normalize()\n",
    "train_mask = dates <= train_end\n",
    "valid_mask = (dates >= valid_start) & (dates <= valid_end)\n",
    "test_mask = dates >= test_start\n",
    "\n",
    "# Split data\n",
    "train_df = full_df[train_mask].copy()\n",
    "valid_df = full_df[valid_mask].copy()\n",
    "test_df = full_df[test_mask].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)} ({train_df.index.min().date()} to {train_df.index.max().date()})\")\n",
    "print(f\"Valid: {len(valid_df)} ({valid_df.index.min().date()} to {valid_df.index.max().date()})\")\n",
    "print(f\"Test:  {len(test_df)} ({test_df.index.min().date()} to {test_df.index.max().date()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "exclude_cols = [TARGET_COL, \"sample_weight\"]\n",
    "feature_cols = [c for c in full_df.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_valid = valid_df[feature_cols].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "\n",
    "y_train = train_df[TARGET_COL].copy()\n",
    "y_valid = valid_df[TARGET_COL].copy()\n",
    "y_test = test_df[TARGET_COL].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "w_cfg = RUN_PARAMS[\"weights\"]\n",
    "w_train = compute_sample_weights(y_train, c=w_cfg[\"c\"], max_w=w_cfg[\"max_w\"])\n",
    "w_valid = compute_sample_weights(y_valid, c=w_cfg[\"c\"], max_w=w_cfg[\"max_w\"])\n",
    "w_test = compute_sample_weights(y_test, c=w_cfg[\"c\"], max_w=w_cfg[\"max_w\"])\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"[OK] Split complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits to data/processed\n",
    "PROC_LOCAL = DATA_DIRS_LOCAL[\"processed\"]\n",
    "PROC_DRIVE = DATA_DIRS_DRIVE[\"processed\"]\n",
    "\n",
    "X_train.to_pickle(PROC_LOCAL / \"X_train_xgb.pkl\")\n",
    "X_valid.to_pickle(PROC_LOCAL / \"X_valid_xgb.pkl\")\n",
    "X_test.to_pickle(PROC_LOCAL / \"X_test_xgb.pkl\")\n",
    "\n",
    "save_pickle(y_train, PROC_LOCAL / \"y_train.pkl\")\n",
    "save_pickle(y_valid, PROC_LOCAL / \"y_valid.pkl\")\n",
    "save_pickle(y_test, PROC_LOCAL / \"y_test.pkl\")\n",
    "\n",
    "save_pickle(w_train, PROC_LOCAL / \"weights_train.pkl\")\n",
    "save_pickle(w_valid, PROC_LOCAL / \"weights_valid.pkl\")\n",
    "save_pickle(w_test, PROC_LOCAL / \"weights_test.pkl\")\n",
    "\n",
    "# Copy to Drive\n",
    "for f in PROC_LOCAL.glob(\"*.pkl\"):\n",
    "    copy_file(f, PROC_DRIVE / f.name)\n",
    "\n",
    "print(\"[OK] Splits saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. XGBoost Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.xgboost_model import xgb_feature_selection\n",
    "\n",
    "selected_features, gain_df, perm_df = xgb_feature_selection(\n",
    "    X_train, X_valid,\n",
    "    y_train, y_valid,\n",
    "    w_train, w_valid,\n",
    "    config=RUN_PARAMS[\"xgb_fs\"],\n",
    "    output_dir=LOCAL_PATHS[\"fs_dir\"]\n",
    ")\n",
    "\n",
    "# Copy to Drive\n",
    "for f in LOCAL_PATHS[\"fs_dir\"].glob(\"*\"):\n",
    "    copy_file(f, DRIVE_PATHS[\"fs_dir\"] / f.name)\n",
    "\n",
    "print(f\"\\n[OK] Selected {len(selected_features)} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered datasets\n",
    "X_train_sel = X_train[selected_features].copy()\n",
    "X_valid_sel = X_valid[selected_features].copy()\n",
    "X_test_sel = X_test[selected_features].copy()\n",
    "\n",
    "# Save\n",
    "X_train_sel.to_pickle(PROC_LOCAL / \"X_train_xgb_selected.pkl\")\n",
    "X_valid_sel.to_pickle(PROC_LOCAL / \"X_valid_xgb_selected.pkl\")\n",
    "X_test_sel.to_pickle(PROC_LOCAL / \"X_test_xgb_selected.pkl\")\n",
    "\n",
    "for f in [\"X_train_xgb_selected.pkl\", \"X_valid_xgb_selected.pkl\", \"X_test_xgb_selected.pkl\"]:\n",
    "    copy_file(PROC_LOCAL / f, PROC_DRIVE / f)\n",
    "\n",
    "print(f\"[OK] Selected feature datasets saved. Shape: {X_train_sel.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. XGBoost HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.xgboost_model import run_hpo, train_final_model\n",
    "\n",
    "# Split validation for HPO (early stopping vs scoring)\n",
    "hpo_cfg = RUN_PARAMS[\"hpo\"]\n",
    "valid_es_start = hpo_cfg[\"valid_es_start\"]\n",
    "valid_es_end = hpo_cfg[\"valid_es_end\"]\n",
    "valid_score_start = hpo_cfg[\"valid_score_start\"]\n",
    "valid_score_end = hpo_cfg[\"valid_score_end\"]\n",
    "\n",
    "valid_dates = X_valid_sel.index.normalize()\n",
    "es_mask = (valid_dates >= valid_es_start) & (valid_dates <= valid_es_end)\n",
    "score_mask = (valid_dates >= valid_score_start) & (valid_dates <= valid_score_end)\n",
    "\n",
    "X_valid_es = X_valid_sel[es_mask]\n",
    "X_valid_score = X_valid_sel[score_mask]\n",
    "y_valid_es = y_valid[es_mask]\n",
    "y_valid_score = y_valid[score_mask]\n",
    "w_valid_es = w_valid[es_mask]\n",
    "w_valid_score = w_valid[score_mask]\n",
    "\n",
    "print(f\"Valid ES: {len(X_valid_es)} | Valid Score: {len(X_valid_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HPO\n",
    "best_params, all_trials = run_hpo(\n",
    "    X_train_sel,\n",
    "    X_valid_es, X_valid_score,\n",
    "    y_train, y_valid_es, y_valid_score,\n",
    "    w_train, w_valid_es, w_valid_score,\n",
    "    config=hpo_cfg,\n",
    "    random_state=RUN_PARAMS[\"random_state\"]\n",
    ")\n",
    "\n",
    "# Save HPO results\n",
    "save_json(best_params, LOCAL_PATHS[\"ms_dir\"] / \"best_params.json\")\n",
    "save_pickle(all_trials, LOCAL_PATHS[\"ms_dir\"] / \"hpo_trials.pkl\")\n",
    "\n",
    "copy_file(LOCAL_PATHS[\"ms_dir\"] / \"best_params.json\", DRIVE_PATHS[\"ms_dir\"] / \"best_params.json\")\n",
    "\n",
    "print(f\"\\n[OK] HPO complete. Best params saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Train Final XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "xgb_model, xgb_metrics = train_final_model(\n",
    "    X_train_sel, X_valid_sel, X_test_sel,\n",
    "    y_train, y_valid, y_test,\n",
    "    w_train, w_valid, w_test,\n",
    "    params=best_params,\n",
    "    config=hpo_cfg\n",
    ")\n",
    "\n",
    "# Save model\n",
    "xgb_model.save_model(str(LOCAL_PATHS[\"models_dir\"] / \"xgb_final.json\"))\n",
    "copy_file(LOCAL_PATHS[\"models_dir\"] / \"xgb_final.json\", DRIVE_PATHS[\"models_dir\"] / \"xgb_final.json\")\n",
    "\n",
    "# Save metrics\n",
    "save_json(xgb_metrics, LOCAL_PATHS[\"outputs_dir\"] / \"xgb_metrics.json\")\n",
    "\n",
    "print(f\"\\n[OK] XGBoost training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.neural import train_lstm, train_gru, train_hybrid_sequential, train_hybrid_parallel\n",
    "\n",
    "# Collect results\n",
    "all_results = []\n",
    "\n",
    "# Add XGBoost result\n",
    "all_results.append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"model\": \"XGBoost\",\n",
    "    \"feature_set\": \"xgb_selected\",\n",
    "    \"test_wrmse\": xgb_metrics[\"test_wrmse\"],\n",
    "    \"test_diracc\": xgb_metrics[\"test_diracc\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM\n",
    "lstm_model, lstm_results = train_lstm(\n",
    "    X_train_sel, X_valid_sel, X_test_sel,\n",
    "    y_train, y_valid, y_test,\n",
    "    config=RUN_PARAMS[\"lstm\"],\n",
    "    output_dir=LOCAL_PATHS[\"models_dir\"]\n",
    ")\n",
    "\n",
    "all_results.append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"model\": \"LSTM\",\n",
    "    \"feature_set\": \"xgb_selected\",\n",
    "    \"test_wrmse\": lstm_results[\"metrics\"][\"test_wrmse\"],\n",
    "    \"test_diracc\": lstm_results[\"metrics\"][\"test_diracc\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU\n",
    "gru_model, gru_results = train_gru(\n",
    "    X_train_sel, X_valid_sel, X_test_sel,\n",
    "    y_train, y_valid, y_test,\n",
    "    config=RUN_PARAMS[\"gru\"],\n",
    "    output_dir=LOCAL_PATHS[\"models_dir\"]\n",
    ")\n",
    "\n",
    "all_results.append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"model\": \"GRU\",\n",
    "    \"feature_set\": \"xgb_selected\",\n",
    "    \"test_wrmse\": gru_results[\"metrics\"][\"test_wrmse\"],\n",
    "    \"test_diracc\": gru_results[\"metrics\"][\"test_diracc\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid Sequential\n",
    "hybrid_seq_model, hybrid_seq_results = train_hybrid_sequential(\n",
    "    X_train_sel, X_valid_sel, X_test_sel,\n",
    "    y_train, y_valid, y_test,\n",
    "    config=RUN_PARAMS[\"hybrid_seq\"],\n",
    "    output_dir=LOCAL_PATHS[\"models_dir\"]\n",
    ")\n",
    "\n",
    "all_results.append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"model\": \"Hybrid-Seq\",\n",
    "    \"feature_set\": \"xgb_selected\",\n",
    "    \"test_wrmse\": hybrid_seq_results[\"metrics\"][\"test_wrmse\"],\n",
    "    \"test_diracc\": hybrid_seq_results[\"metrics\"][\"test_diracc\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid Parallel\n",
    "hybrid_par_model, hybrid_par_results = train_hybrid_parallel(\n",
    "    X_train_sel, X_valid_sel, X_test_sel,\n",
    "    y_train, y_valid, y_test,\n",
    "    config=RUN_PARAMS[\"hybrid_par\"],\n",
    "    output_dir=LOCAL_PATHS[\"models_dir\"]\n",
    ")\n",
    "\n",
    "all_results.append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"model\": \"Hybrid-Par\",\n",
    "    \"feature_set\": \"xgb_selected\",\n",
    "    \"test_wrmse\": hybrid_par_results[\"metrics\"][\"test_wrmse\"],\n",
    "    \"test_diracc\": hybrid_par_results[\"metrics\"][\"test_diracc\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values(\"test_wrmse\").reset_index(drop=True)\n",
    "results_df.insert(0, \"rank\", range(1, len(results_df) + 1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "display(results_df)\n",
    "\n",
    "# Best model\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nBest Model: {best['model']}\")\n",
    "print(f\"Test wRMSE: {best['test_wrmse']:.6f}\")\n",
    "print(f\"Test DirAcc: {best['test_diracc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv(LOCAL_PATHS[\"outputs_dir\"] / \"results_summary.csv\", index=False)\n",
    "copy_file(LOCAL_PATHS[\"outputs_dir\"] / \"results_summary.csv\", \n",
    "          DRIVE_PATHS[\"outputs_dir\"] / \"results_summary.csv\")\n",
    "\n",
    "print(f\"\\n[OK] Results saved to {LOCAL_PATHS['outputs_dir']}\")\n",
    "print(f\"[OK] Pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
